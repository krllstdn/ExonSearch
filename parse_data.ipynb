{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e519ca86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 23:48:52.383860: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-02 23:48:52.384284: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-02 23:48:52.386835: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-02 23:48:52.392647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746222532.401690 2839058 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746222532.404387 2839058 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746222532.411947 2839058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746222532.411957 2839058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746222532.411959 2839058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746222532.411959 2839058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-02 23:48:52.414647: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Parse GTF and group exons by gene\n",
    "# gtf = pd.read_csv('data/Homo_sapiens.GRCh38.113.chr.gtf.gz', sep='\\t', comment='#', header=None,\n",
    "#                   names=['chr', 'source', 'feature', 'start', 'end', 'score',\n",
    "#                          'strand', 'frame', 'attributes'])\n",
    "# exons = gtf[gtf['feature'] == 'exon']\n",
    "# exons = gtf[gtf['chr'] == '21']\n",
    "# exons['gene_id'] = exons['attributes'].str.extract('gene_id \"([^\"]+)\"')\n",
    "# genes = exons.groupby('gene_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d25cfc83-7716-4fc6-a0bf-3afeb0d67281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "WINDOW_SIZE = 101\n",
    "CHROMOSOME_PREFIX = \"\"  # \"chr\" if needed to match FASTA\n",
    "RANDOM_SEED = 42\n",
    "LEARNING_RATE = 0.0005\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3b8aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split genes into train/test\n",
    "# gene_ids = list(genes.groups.key())\n",
    "# train_genes, test_genes = train_test_split(gene_ids, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85bf38dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gtf(gtf_path):\n",
    "    \"\"\"Parse GTF file and return exon positions grouped by gene\"\"\"\n",
    "    gtf = pd.read_csv(\n",
    "        gtf_path,\n",
    "        sep='\\t',\n",
    "        comment='#',\n",
    "        header=None,\n",
    "        names=[\n",
    "            'chr', 'source', 'feature', 'start', 'end',\n",
    "            'score', 'strand', 'frame', 'attributes'\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Filter exons and extract gene IDs\n",
    "    exons = gtf[gtf['feature'] == 'exon'].copy()\n",
    "    exons['gene_id'] = exons['attributes'].str.extract(r'gene_id \"([^\"]+)\"')\n",
    "    exons['chr'] = CHROMOSOME_PREFIX + exons['chr'].astype(str)\n",
    "    \n",
    "    # Group exons by gene\n",
    "    return exons.groupby('gene_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bf48614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples_for_gene(gene_data, chromosomes, window_size=101):\n",
    "    \"\"\"Generate samples for a single gene\"\"\"\n",
    "    sequences, labels = [], []\n",
    "    half_window = window_size // 2\n",
    "    chr_name = gene_data['chr'].iloc[0]\n",
    "    \n",
    "    if chr_name not in chromosomes:\n",
    "        return [], []\n",
    "    \n",
    "    chr_seq = str(chromosomes[chr_name].seq)\n",
    "    exon_starts = set(gene_data['start'].values)\n",
    "    gene_start = gene_data['start'].min()\n",
    "    gene_end = gene_data['end'].max()\n",
    "\n",
    "    # Positive samples\n",
    "    for start_pos in exon_starts:\n",
    "        window_start = start_pos - half_window - 1\n",
    "        window_end = window_start + window_size\n",
    "        \n",
    "        if 0 <= window_start < len(chr_seq) and window_end <= len(chr_seq):\n",
    "            seq = chr_seq[window_start:window_end]\n",
    "            sequences.append(one_hot_encode(seq))\n",
    "            labels.append(1)\n",
    "\n",
    "    # Negative samples\n",
    "    num_neg = len(exon_starts)\n",
    "    attempts = 0\n",
    "    max_attempts = num_neg * 10\n",
    "    \n",
    "    while len(labels) - sum(labels) < num_neg and attempts < max_attempts:\n",
    "        rand_pos = np.random.randint(gene_start, gene_end)\n",
    "        if rand_pos not in exon_starts:\n",
    "            window_start = rand_pos - half_window - 1\n",
    "            window_end = window_start + window_size\n",
    "            \n",
    "            if 0 <= window_start < len(chr_seq) and window_end <= len(chr_seq):\n",
    "                seq = chr_seq[window_start:window_end]\n",
    "                sequences.append(one_hot_encode(seq))\n",
    "                labels.append(0)\n",
    "        attempts += 1\n",
    "\n",
    "    return sequences, labels\n",
    "\n",
    "def one_hot_encode(seq):\n",
    "    mapping = {'A': [1,0,0,0], 'T': [0,1,0,0],\n",
    "               'C': [0,0,1,0], 'G': [0,0,0,1]}\n",
    "    return [mapping.get(nuc, [0,0,0,0]) for nuc in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ccaf5b-6b82-4604-b5ce-aefc6e819d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Model Architecture\n",
    "# def build_model(input_shape):\n",
    "#     model = tf.keras.Sequential([\n",
    "#         tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "#         tf.keras.layers.Conv1D(64, 10, activation='relu'),\n",
    "#         tf.keras.layers.MaxPooling1D(2),\n",
    "#         tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "#         tf.keras.layers.GlobalMaxPooling1D(),\n",
    "#         tf.keras.layers.Dense(64, activation='relu'),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "#         tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "#     ])\n",
    "    \n",
    "#     model.compile(\n",
    "#         optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#         loss='binary_crossentropy',\n",
    "#         metrics=['accuracy', \n",
    "#                  tf.keras.metrics.Precision(name='precision'),\n",
    "#                  tf.keras.metrics.Recall(name='recall')]\n",
    "#     )\n",
    "#     return model\n",
    "# def build_model(input_shape):\n",
    "#     inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "#     x = tf.keras.layers.Conv1D(64, kernel_size=15, padding='valid', activation='relu')(inputs)\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "#     x = tf.keras.layers.Conv1D(128, kernel_size=5, padding='valid', activation='relu')(x)\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "#     x = tf.keras.layers.Conv1D(256, kernel_size=3, padding='valid', activation='relu')(x)\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "#     # attention section\n",
    "#     attn = tf.keras.layers.Conv1D(1, kernel_size=1)(x)\n",
    "#     attn = tf.keras.layers.Softmax(axis=1)(attn)\n",
    "#     x = tf.keras.layers.Multiply()([x, attn])\n",
    "#     x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "#     x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "#     x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "#     outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "#     model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "#     model.compile(\n",
    "#         optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#         loss='binary_crossentropy',\n",
    "#         metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "#     )\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccaf5b7a-52cd-45d3-a02a-276babf41071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv1D(64, kernel_size=10, activation='relu')(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(128, kernel_size=5, activation='relu')(x)\n",
    "\n",
    "    # Attention layer\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    #     initial_learning_rate=0.0003,\n",
    "    #     decay_steps=10000\n",
    "    # )\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4f49a3e-7d18-40b6-9401-2609e583a9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2839058/3023959441.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gtf = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "\n",
    "chromosomes = SeqIO.to_dict(SeqIO.parse('data/Homo_sapiens.GRCh38.dna.chromosome.21.fa', 'fasta'))\n",
    "\n",
    "gene_groups = parse_gtf(\"data/Homo_sapiens.GRCh38.113.chr.gtf.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24e9df-fc5e-45a3-83da-76373e75604c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2839058/3023959441.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gtf = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 62979/62979 [09:06<00:00, 115.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 15745/15745 [02:20<00:00, 112.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split genes\n",
    "gene_ids = list(gene_groups.groups.keys())\n",
    "train_genes, test_genes = train_test_split(\n",
    "    gene_ids, test_size=0.2, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Generate samples\n",
    "print(\"Processing training data...\")\n",
    "X_train, y_train = [], []\n",
    "for gene_id in tqdm(train_genes):\n",
    "    try:\n",
    "        gene_data = gene_groups.get_group(gene_id)\n",
    "        seqs, lbls = generate_samples_for_gene(gene_data, chromosomes)\n",
    "        X_train.extend(seqs)\n",
    "        y_train.extend(lbls)\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "print(\"Processing test data...\")\n",
    "X_test, y_test = [], []\n",
    "for gene_id in tqdm(test_genes):\n",
    "    try:\n",
    "        gene_data = gene_groups.get_group(gene_id)\n",
    "        seqs, lbls = generate_samples_for_gene(gene_data, chromosomes)\n",
    "        X_test.extend(seqs)\n",
    "        y_test.extend(lbls)\n",
    "    except KeyError:\n",
    "        continue\n",
    "# Convert to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c75945e-da68-4bd9-a4d6-7964296d248b",
   "metadata": {},
   "source": [
    "# Note\n",
    "The problem was to load and process data without memory blow up. I tried to speed things up (1st chromosome took too long in comparison with 21st, the shortest one) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee87ed4a-9fca-4437-87c7-b5c0f83e9af5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                                       | 1703/62979 [00:14<08:37, 118.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m X_data, y_data\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Load and preprocess all data before training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m X_train, y_train = \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_genes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgene_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchromosomes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWINDOW_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m X_test, y_test = preprocess_data(test_genes, gene_groups, chromosomes, WINDOW_SIZE)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mpreprocess_data\u001b[39m\u001b[34m(gene_ids, gene_groups, chromosomes, window_size)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      6\u001b[39m     gene_data = gene_groups.get_group(gene_id)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     seqs, lbls = \u001b[43mgenerate_samples_for_gene\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgene_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchromosomes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m seqs:\n\u001b[32m      9\u001b[39m         X_data.extend(seqs)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mgenerate_samples_for_gene\u001b[39m\u001b[34m(gene_data, chromosomes, window_size)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chr_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m chromosomes:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [], []\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m chr_seq = \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchromosomes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchr_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m exon_starts = \u001b[38;5;28mset\u001b[39m(gene_data[\u001b[33m'\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m'\u001b[39m].values)\n\u001b[32m     12\u001b[39m gene_start = gene_data[\u001b[33m'\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m'\u001b[39m].min()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ExonSearch/venv/lib/python3.12/site-packages/Bio/Seq.py:410\u001b[39m, in \u001b[36m_SeqAbstractBaseClass.__str__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    409\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the full sequence as a python string.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mASCII\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_data(gene_ids, gene_groups, chromosomes, window_size):\n",
    "    \"\"\"Preprocess all data into memory before training.\"\"\"\n",
    "    X_data, y_data = [], []\n",
    "    for gene_id in tqdm(gene_ids):\n",
    "        try:\n",
    "            gene_data = gene_groups.get_group(gene_id)\n",
    "            seqs, lbls = generate_samples_for_gene(gene_data, chromosomes, window_size)\n",
    "            if seqs:\n",
    "                X_data.extend(seqs)\n",
    "                y_data.extend(lbls)\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    X_data = np.array(X_data, dtype=np.uint8)  # Store sequences\n",
    "    y_data = np.array(y_data, dtype=np.uint8)  # Store labels\n",
    "    \n",
    "    return X_data, y_data\n",
    "\n",
    "# Load and preprocess all data before training\n",
    "X_train, y_train = preprocess_data(train_genes, gene_groups, chromosomes, WINDOW_SIZE)\n",
    "X_test, y_test = preprocess_data(test_genes, gene_groups, chromosomes, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dbabea4b-c9f5-44c3-bc38-147c9a0230e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "HDF5ExtError",
     "evalue": "HDF5 error back trace\n\n  File \"H5F.c\", line 836, in H5Fopen\n    unable to synchronously open file\n  File \"H5F.c\", line 796, in H5F__open_api_common\n    unable to open file\n  File \"H5VLcallback.c\", line 3863, in H5VL_file_open\n    open failed\n  File \"H5VLcallback.c\", line 3675, in H5VL__file_open\n    open failed\n  File \"H5VLnative_file.c\", line 128, in H5VL__native_file_open\n    unable to open file\n  File \"H5Fint.c\", line 1910, in H5F_open\n    unable to lock the file\n  File \"H5FD.c\", line 2412, in H5FD_lock\n    driver lock request failed\n  File \"H5FDsec2.c\", line 941, in H5FD__sec2_lock\n    unable to lock file, errno = 11, error message = 'Resource temporarily unavailable'\n\nEnd of HDF5 error back trace\n\nUnable to open/create file 'genes.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHDF5ExtError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m f.create_dataset(\u001b[33m'\u001b[39m\u001b[33mtrain_genes\u001b[39m\u001b[33m'\u001b[39m, data=train_genes)\n\u001b[32m      5\u001b[39m f.create_dataset(\u001b[33m'\u001b[39m\u001b[33mtest_genes\u001b[39m\u001b[33m'\u001b[39m, data=test_genes)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mgene_groups\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_hdf\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgenes.h5\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgene_df\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ma\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ExonSearch/venv/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ExonSearch/venv/lib/python3.12/site-packages/pandas/core/generic.py:2855\u001b[39m, in \u001b[36mNDFrame.to_hdf\u001b[39m\u001b[34m(self, path_or_buf, key, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\u001b[39m\n\u001b[32m   2851\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pytables\n\u001b[32m   2853\u001b[39m \u001b[38;5;66;03m# Argument 3 to \"to_hdf\" has incompatible type \"NDFrame\"; expected\u001b[39;00m\n\u001b[32m   2854\u001b[39m \u001b[38;5;66;03m# \"Union[DataFrame, Series]\" [arg-type]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2855\u001b[39m \u001b[43mpytables\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_hdf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2857\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2858\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2859\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2860\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomplevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomplevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2861\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomplib\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomplib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2862\u001b[39m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2863\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2864\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2865\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_itemsize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_itemsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2866\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnan_rep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnan_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2867\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2868\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2869\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2871\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ExonSearch/venv/lib/python3.12/site-packages/pandas/io/pytables.py:308\u001b[39m, in \u001b[36mto_hdf\u001b[39m\u001b[34m(path_or_buf, key, value, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\u001b[39m\n\u001b[32m    306\u001b[39m path_or_buf = stringify_path(path_or_buf)\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mHDFStore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomplevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplib\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomplib\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m store:\n\u001b[32m    311\u001b[39m         f(store)\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ExonSearch/venv/lib/python3.12/site-packages/pandas/io/pytables.py:585\u001b[39m, in \u001b[36mHDFStore.__init__\u001b[39m\u001b[34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[39m\n\u001b[32m    583\u001b[39m \u001b[38;5;28mself\u001b[39m._fletcher32 = fletcher32\n\u001b[32m    584\u001b[39m \u001b[38;5;28mself\u001b[39m._filters = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m585\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ExonSearch/venv/lib/python3.12/site-packages/pandas/io/pytables.py:745\u001b[39m, in \u001b[36mHDFStore.open\u001b[39m\u001b[34m(self, mode, **kwargs)\u001b[39m\n\u001b[32m    739\u001b[39m     msg = (\n\u001b[32m    740\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot open HDF5 file, which is already opened, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    741\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33meven in read-only mode.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    742\u001b[39m     )\n\u001b[32m    743\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m \u001b[38;5;28mself\u001b[39m._handle = \u001b[43mtables\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ExonSearch/venv/lib/python3.12/site-packages/tables/file.py:325\u001b[39m, in \u001b[36mopen_file\u001b[39m\u001b[34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mThe file \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is already opened.  Please \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mclose it before reopening in write mode.\u001b[39m\u001b[33m\"\u001b[39m % filename\n\u001b[32m    322\u001b[39m             )\n\u001b[32m    324\u001b[39m \u001b[38;5;66;03m# Finally, create the File instance, and return it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot_uep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ExonSearch/venv/lib/python3.12/site-packages/tables/file.py:811\u001b[39m, in \u001b[36mFile.__init__\u001b[39m\u001b[34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[39m\n\u001b[32m    808\u001b[39m \u001b[38;5;28mself\u001b[39m.params = params\n\u001b[32m    810\u001b[39m \u001b[38;5;66;03m# Now, it is time to initialize the File extension\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m811\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_g_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    813\u001b[39m \u001b[38;5;66;03m# Check filters and set PyTables format version for new files.\u001b[39;00m\n\u001b[32m    814\u001b[39m new = \u001b[38;5;28mself\u001b[39m._v_new\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ExonSearch/venv/lib/python3.12/site-packages/tables/hdf5extension.pyx:617\u001b[39m, in \u001b[36mtables.hdf5extension.File._g_new\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mHDF5ExtError\u001b[39m: HDF5 error back trace\n\n  File \"H5F.c\", line 836, in H5Fopen\n    unable to synchronously open file\n  File \"H5F.c\", line 796, in H5F__open_api_common\n    unable to open file\n  File \"H5VLcallback.c\", line 3863, in H5VL_file_open\n    open failed\n  File \"H5VLcallback.c\", line 3675, in H5VL__file_open\n    open failed\n  File \"H5VLnative_file.c\", line 128, in H5VL__native_file_open\n    unable to open file\n  File \"H5Fint.c\", line 1910, in H5F_open\n    unable to lock the file\n  File \"H5FD.c\", line 2412, in H5FD_lock\n    driver lock request failed\n  File \"H5FDsec2.c\", line 941, in H5FD__sec2_lock\n    unable to lock file, errno = 11, error message = 'Resource temporarily unavailable'\n\nEnd of HDF5 error back trace\n\nUnable to open/create file 'genes.h5'"
     ]
    }
   ],
   "source": [
    "with h5py.File(f'genes.h5', 'w') as f:\n",
    "    # Save the tuple as a dataset\n",
    "    # f.create_dataset('gene_groups', data=gene_groups)\n",
    "    f.create_dataset('train_genes', data=train_genes)\n",
    "    f.create_dataset('test_genes', data=test_genes)\n",
    "    gene_groups.obj.to_hdf('genes.h5', key='gene_df', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0aa9d5e-e399-4546-b6da-1a3987837979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading gtf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2839058/3023959441.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gtf = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting_genes...\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "print(\"loading gtf...\") \n",
    "gene_groups = parse_gtf(\"data/Homo_sapiens.GRCh38.113.chr.gtf.gz\") # must be outside loop\n",
    "\n",
    "# Split genes\n",
    "print(\"splitting_genes...\")\n",
    "gene_ids = list(gene_groups.groups.keys())\n",
    "train_genes, test_genes = train_test_split(\n",
    "    gene_ids, test_size=0.2, random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5388076-58d6-4d19-9892-2883e9d7e096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chromosome X...\n",
      "This chromosome (X) has already been processed. Loading train/test data....\n",
      "train model on chomosome X.....\n",
      "Epoch 1/35\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 121ms/step - accuracy: 0.5423 - loss: 0.6883 - precision_12: 0.5413 - recall_12: 0.5352 - val_accuracy: 0.6174 - val_loss: 0.6548 - val_precision_12: 0.5982 - val_recall_12: 0.7147\n",
      "Epoch 2/35\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 108ms/step - accuracy: 0.6176 - loss: 0.6538 - precision_12: 0.6121 - recall_12: 0.6422 - val_accuracy: 0.6815 - val_loss: 0.6043 - val_precision_12: 0.7031 - val_recall_12: 0.6282\n",
      "Epoch 3/35\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 107ms/step - accuracy: 0.6786 - loss: 0.6039 - precision_12: 0.6876 - recall_12: 0.6539 - val_accuracy: 0.6876 - val_loss: 0.5901 - val_precision_12: 0.7218 - val_recall_12: 0.6106\n",
      "Epoch 4/35\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - accuracy: 0.7086 - loss: 0.5726 - precision_12: 0.7128 - recall_12: 0.6977 - val_accuracy: 0.6824 - val_loss: 0.5969 - val_precision_12: 0.7445 - val_recall_12: 0.5553\n",
      "Epoch 5/35\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - accuracy: 0.7238 - loss: 0.5503 - precision_12: 0.7286 - recall_12: 0.7123 - val_accuracy: 0.6965 - val_loss: 0.5903 - val_precision_12: 0.7266 - val_recall_12: 0.6300\n",
      "Epoch 6/35\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.7362 - loss: 0.5335 - precision_12: 0.7376 - recall_12: 0.7326 - val_accuracy: 0.6941 - val_loss: 0.6026 - val_precision_12: 0.7288 - val_recall_12: 0.6182\n",
      "Epoch 7/35\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 104ms/step - accuracy: 0.7541 - loss: 0.5087 - precision_12: 0.7552 - recall_12: 0.7510 - val_accuracy: 0.6944 - val_loss: 0.6154 - val_precision_12: 0.7202 - val_recall_12: 0.6359\n",
      "Epoch 8/35\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.7695 - loss: 0.4906 - precision_12: 0.7690 - recall_12: 0.7698 - val_accuracy: 0.6856 - val_loss: 0.6382 - val_precision_12: 0.7217 - val_recall_12: 0.6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "260/260 - 2s - 8ms/step - accuracy: 0.6924 - loss: 0.5912 - precision_12: 0.7171 - recall_12: 0.6353\n",
      "Processing chromosome 20...\n",
      "This chromosome (20) has already been processed. Loading train/test data....\n",
      "train model on chomosome 20.....\n",
      "Epoch 1/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - accuracy: 0.6997 - loss: 0.5812 - precision_12: 0.7006 - recall_12: 0.6920 - val_accuracy: 0.6959 - val_loss: 0.5831 - val_precision_12: 0.6994 - val_recall_12: 0.6703\n",
      "Epoch 2/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - accuracy: 0.7212 - loss: 0.5552 - precision_12: 0.7220 - recall_12: 0.7148 - val_accuracy: 0.6986 - val_loss: 0.5809 - val_precision_12: 0.6918 - val_recall_12: 0.6994\n",
      "Epoch 3/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - accuracy: 0.7391 - loss: 0.5359 - precision_12: 0.7370 - recall_12: 0.7392 - val_accuracy: 0.6940 - val_loss: 0.5849 - val_precision_12: 0.6944 - val_recall_12: 0.6758\n",
      "Epoch 4/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - accuracy: 0.7561 - loss: 0.5168 - precision_12: 0.7570 - recall_12: 0.7507 - val_accuracy: 0.6893 - val_loss: 0.5953 - val_precision_12: 0.6733 - val_recall_12: 0.7166\n",
      "Epoch 5/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 95ms/step - accuracy: 0.7729 - loss: 0.4961 - precision_12: 0.7716 - recall_12: 0.7721 - val_accuracy: 0.6785 - val_loss: 0.6124 - val_precision_12: 0.6590 - val_recall_12: 0.7190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "226/226 - 2s - 9ms/step - accuracy: 0.7060 - loss: 0.5721 - precision_12: 0.7109 - recall_12: 0.6943\n",
      "Processing chromosome 16...\n",
      "This chromosome (16) has already been processed. Loading train/test data....\n",
      "train model on chomosome 16.....\n",
      "Epoch 1/35\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 99ms/step - accuracy: 0.6943 - loss: 0.5881 - precision_12: 0.6962 - recall_12: 0.6943 - val_accuracy: 0.7149 - val_loss: 0.5643 - val_precision_12: 0.6984 - val_recall_12: 0.7539\n",
      "Epoch 2/35\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 104ms/step - accuracy: 0.7106 - loss: 0.5698 - precision_12: 0.7153 - recall_12: 0.7036 - val_accuracy: 0.7181 - val_loss: 0.5643 - val_precision_12: 0.6971 - val_recall_12: 0.7687\n",
      "Epoch 3/35\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 97ms/step - accuracy: 0.7213 - loss: 0.5569 - precision_12: 0.7264 - recall_12: 0.7140 - val_accuracy: 0.7162 - val_loss: 0.5698 - val_precision_12: 0.6902 - val_recall_12: 0.7818\n",
      "Epoch 4/35\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - accuracy: 0.7313 - loss: 0.5467 - precision_12: 0.7397 - recall_12: 0.7174 - val_accuracy: 0.7168 - val_loss: 0.5684 - val_precision_12: 0.6990 - val_recall_12: 0.7590\n",
      "Epoch 5/35\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 99ms/step - accuracy: 0.7423 - loss: 0.5308 - precision_12: 0.7517 - recall_12: 0.7271 - val_accuracy: 0.7122 - val_loss: 0.5799 - val_precision_12: 0.6917 - val_recall_12: 0.7628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "384/384 - 4s - 10ms/step - accuracy: 0.7051 - loss: 0.5696 - precision_12: 0.6879 - recall_12: 0.7510\n",
      "Processing chromosome 19...\n",
      "This chromosome (19) has already been processed. Loading train/test data....\n",
      "train model on chomosome 19.....\n",
      "Epoch 1/35\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 103ms/step - accuracy: 0.7194 - loss: 0.5588 - precision_12: 0.7229 - recall_12: 0.7091 - val_accuracy: 0.7205 - val_loss: 0.5525 - val_precision_12: 0.7040 - val_recall_12: 0.7596\n",
      "Epoch 2/35\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 95ms/step - accuracy: 0.7344 - loss: 0.5405 - precision_12: 0.7385 - recall_12: 0.7237 - val_accuracy: 0.7236 - val_loss: 0.5500 - val_precision_12: 0.7158 - val_recall_12: 0.7408\n",
      "Epoch 3/35\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 105ms/step - accuracy: 0.7439 - loss: 0.5302 - precision_12: 0.7491 - recall_12: 0.7314 - val_accuracy: 0.7246 - val_loss: 0.5534 - val_precision_12: 0.7187 - val_recall_12: 0.7370\n",
      "Epoch 4/35\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 98ms/step - accuracy: 0.7562 - loss: 0.5154 - precision_12: 0.7620 - recall_12: 0.7432 - val_accuracy: 0.7197 - val_loss: 0.5573 - val_precision_12: 0.7089 - val_recall_12: 0.7446\n",
      "Epoch 5/35\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.7633 - loss: 0.5038 - precision_12: 0.7699 - recall_12: 0.7493 - val_accuracy: 0.7184 - val_loss: 0.5670 - val_precision_12: 0.7074 - val_recall_12: 0.7438\n",
      "Epoch 6/35\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 102ms/step - accuracy: 0.7769 - loss: 0.4897 - precision_12: 0.7834 - recall_12: 0.7639 - val_accuracy: 0.7156 - val_loss: 0.5759 - val_precision_12: 0.6981 - val_recall_12: 0.7585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "424/424 - 4s - 9ms/step - accuracy: 0.7163 - loss: 0.5659 - precision_12: 0.7107 - recall_12: 0.7295\n",
      "Processing chromosome Y...\n",
      "This chromosome (Y) has already been processed. Loading train/test data....\n",
      "train model on chomosome Y.....\n",
      "Epoch 1/35\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.6771 - loss: 0.6022 - precision_12: 0.6850 - recall_12: 0.6489 - val_accuracy: 0.7250 - val_loss: 0.5511 - val_precision_12: 0.6919 - val_recall_12: 0.8050\n",
      "Epoch 2/35\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.7073 - loss: 0.5637 - precision_12: 0.7097 - recall_12: 0.6983 - val_accuracy: 0.7516 - val_loss: 0.5378 - val_precision_12: 0.7166 - val_recall_12: 0.8270\n",
      "Epoch 3/35\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.7253 - loss: 0.5360 - precision_12: 0.7276 - recall_12: 0.7178 - val_accuracy: 0.7469 - val_loss: 0.5284 - val_precision_12: 0.7120 - val_recall_12: 0.8239\n",
      "Epoch 4/35\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.7505 - loss: 0.5117 - precision_12: 0.7590 - recall_12: 0.7316 - val_accuracy: 0.7594 - val_loss: 0.5214 - val_precision_12: 0.7579 - val_recall_12: 0.7579\n",
      "Epoch 5/35\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.7738 - loss: 0.4676 - precision_12: 0.7864 - recall_12: 0.7483 - val_accuracy: 0.7406 - val_loss: 0.5341 - val_precision_12: 0.7159 - val_recall_12: 0.7925\n",
      "Epoch 6/35\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.8074 - loss: 0.4304 - precision_12: 0.8107 - recall_12: 0.7996 - val_accuracy: 0.7328 - val_loss: 0.5412 - val_precision_12: 0.7276 - val_recall_12: 0.7390\n",
      "Epoch 7/35\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.8451 - loss: 0.3706 - precision_12: 0.8570 - recall_12: 0.8260 - val_accuracy: 0.7281 - val_loss: 0.6091 - val_precision_12: 0.7264 - val_recall_12: 0.7264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "56/56 - 0s - 9ms/step - accuracy: 0.7192 - loss: 0.5440 - precision_12: 0.7297 - recall_12: 0.6962\n",
      "Processing chromosome 8...\n",
      "This chromosome (8) has already been processed. Loading train/test data....\n",
      "train model on chomosome 8.....\n",
      "Epoch 1/35\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 97ms/step - accuracy: 0.7015 - loss: 0.5839 - precision_12: 0.7191 - recall_12: 0.6688 - val_accuracy: 0.7050 - val_loss: 0.5709 - val_precision_12: 0.7304 - val_recall_12: 0.6450\n",
      "Epoch 2/35\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 95ms/step - accuracy: 0.7197 - loss: 0.5600 - precision_12: 0.7288 - recall_12: 0.7066 - val_accuracy: 0.7081 - val_loss: 0.5711 - val_precision_12: 0.7221 - val_recall_12: 0.6717\n",
      "Epoch 3/35\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 107ms/step - accuracy: 0.7304 - loss: 0.5453 - precision_12: 0.7376 - recall_12: 0.7215 - val_accuracy: 0.7035 - val_loss: 0.5780 - val_precision_12: 0.7195 - val_recall_12: 0.6619\n",
      "Epoch 4/35\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 97ms/step - accuracy: 0.7426 - loss: 0.5301 - precision_12: 0.7494 - recall_12: 0.7348 - val_accuracy: 0.7000 - val_loss: 0.5879 - val_precision_12: 0.7154 - val_recall_12: 0.6588\n",
      "Epoch 5/35\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 99ms/step - accuracy: 0.7568 - loss: 0.5122 - precision_12: 0.7629 - recall_12: 0.7507 - val_accuracy: 0.6986 - val_loss: 0.6074 - val_precision_12: 0.7383 - val_recall_12: 0.6104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "352/352 - 3s - 8ms/step - accuracy: 0.7198 - loss: 0.5558 - precision_12: 0.7285 - recall_12: 0.7005\n",
      "Processing chromosome 22...\n",
      "This chromosome (22) has already been processed. Loading train/test data....\n",
      "train model on chomosome 22.....\n",
      "Epoch 1/35\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.7183 - loss: 0.5592 - precision_12: 0.7246 - recall_12: 0.7032 - val_accuracy: 0.7265 - val_loss: 0.5502 - val_precision_12: 0.7121 - val_recall_12: 0.7601\n",
      "Epoch 2/35\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - accuracy: 0.7349 - loss: 0.5419 - precision_12: 0.7382 - recall_12: 0.7271 - val_accuracy: 0.7232 - val_loss: 0.5591 - val_precision_12: 0.7061 - val_recall_12: 0.7643\n",
      "Epoch 3/35\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 102ms/step - accuracy: 0.7504 - loss: 0.5266 - precision_12: 0.7528 - recall_12: 0.7450 - val_accuracy: 0.7215 - val_loss: 0.5595 - val_precision_12: 0.7114 - val_recall_12: 0.7449\n",
      "Epoch 4/35\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.7622 - loss: 0.5078 - precision_12: 0.7666 - recall_12: 0.7534 - val_accuracy: 0.7186 - val_loss: 0.5747 - val_precision_12: 0.6982 - val_recall_12: 0.7694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "183/183 - 2s - 10ms/step - accuracy: 0.7280 - loss: 0.5482 - precision_12: 0.7102 - recall_12: 0.7704\n",
      "Processing chromosome 6...\n",
      "Chromosome 6 was not processed before. Processing...\n",
      "Loading data for chromosome 6....\n",
      "preprocessing train/test data.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 62979/62979 [04:38<00:00, 225.77it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 15745/15745 [01:05<00:00, 240.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model on chomosome 6.....\n",
      "Epoch 1/35\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.7208 - loss: 0.5548 - precision_12: 0.7311 - recall_12: 0.7062 - val_accuracy: 0.7187 - val_loss: 0.5570 - val_precision_12: 0.7472 - val_recall_12: 0.6496\n",
      "Epoch 2/35\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.7341 - loss: 0.5407 - precision_12: 0.7444 - recall_12: 0.7202 - val_accuracy: 0.7186 - val_loss: 0.5641 - val_precision_12: 0.7540 - val_recall_12: 0.6374\n",
      "Epoch 3/35\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.7430 - loss: 0.5300 - precision_12: 0.7523 - recall_12: 0.7316 - val_accuracy: 0.7213 - val_loss: 0.5627 - val_precision_12: 0.7427 - val_recall_12: 0.6656\n",
      "Epoch 4/35\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.7548 - loss: 0.5162 - precision_12: 0.7587 - recall_12: 0.7538 - val_accuracy: 0.7187 - val_loss: 0.5741 - val_precision_12: 0.7529 - val_recall_12: 0.6398\n",
      "Epoch 5/35\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 86ms/step - accuracy: 0.7649 - loss: 0.5029 - precision_12: 0.7685 - recall_12: 0.7644 - val_accuracy: 0.7229 - val_loss: 0.5733 - val_precision_12: 0.7368 - val_recall_12: 0.6816\n",
      "Epoch 6/35\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.7780 - loss: 0.4862 - precision_12: 0.7779 - recall_12: 0.7838 - val_accuracy: 0.7192 - val_loss: 0.5855 - val_precision_12: 0.7229 - val_recall_12: 0.6987\n",
      "Epoch 7/35\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.7887 - loss: 0.4678 - precision_12: 0.7860 - recall_12: 0.7986 - val_accuracy: 0.7105 - val_loss: 0.6052 - val_precision_12: 0.7100 - val_recall_12: 0.6984\n",
      "Epoch 8/35\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 91ms/step - accuracy: 0.8002 - loss: 0.4496 - precision_12: 0.7953 - recall_12: 0.8132 - val_accuracy: 0.7021 - val_loss: 0.6291 - val_precision_12: 0.7018 - val_recall_12: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "418/418 - 3s - 7ms/step - accuracy: 0.7110 - loss: 0.5764 - precision_12: 0.7195 - recall_12: 0.6917\n",
      "Processing chromosome 3...\n",
      "Chromosome 3 was not processed before. Processing...\n",
      "Loading data for chromosome 3....\n",
      "preprocessing train/test data.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 62979/62979 [05:06<00:00, 205.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 15745/15745 [01:16<00:00, 207.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model on chomosome 3.....\n",
      "Epoch 1/35\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 102ms/step - accuracy: 0.7259 - loss: 0.5544 - precision_12: 0.7348 - recall_12: 0.7094 - val_accuracy: 0.7405 - val_loss: 0.5323 - val_precision_12: 0.7623 - val_recall_12: 0.6967\n",
      "Epoch 2/35\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 100ms/step - accuracy: 0.7427 - loss: 0.5322 - precision_12: 0.7543 - recall_12: 0.7223 - val_accuracy: 0.7402 - val_loss: 0.5341 - val_precision_12: 0.7507 - val_recall_12: 0.7168\n",
      "Epoch 3/35\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 107ms/step - accuracy: 0.7538 - loss: 0.5184 - precision_12: 0.7648 - recall_12: 0.7351 - val_accuracy: 0.7339 - val_loss: 0.5411 - val_precision_12: 0.7677 - val_recall_12: 0.6684\n",
      "Epoch 4/35\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 98ms/step - accuracy: 0.7634 - loss: 0.5053 - precision_12: 0.7753 - recall_12: 0.7440 - val_accuracy: 0.7315 - val_loss: 0.5495 - val_precision_12: 0.7498 - val_recall_12: 0.6924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "477/477 - 4s - 9ms/step - accuracy: 0.7344 - loss: 0.5414 - precision_12: 0.7528 - recall_12: 0.6979\n",
      "Processing chromosome 5...\n",
      "This chromosome (5) has already been processed. Loading train/test data....\n",
      "train model on chomosome 5.....\n",
      "Epoch 1/35\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 100ms/step - accuracy: 0.7282 - loss: 0.5478 - precision_12: 0.7436 - recall_12: 0.6997 - val_accuracy: 0.7370 - val_loss: 0.5341 - val_precision_12: 0.7548 - val_recall_12: 0.6989\n",
      "Epoch 2/35\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 103ms/step - accuracy: 0.7398 - loss: 0.5313 - precision_12: 0.7538 - recall_12: 0.7150 - val_accuracy: 0.7359 - val_loss: 0.5375 - val_precision_12: 0.7656 - val_recall_12: 0.6768\n",
      "Epoch 3/35\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 102ms/step - accuracy: 0.7519 - loss: 0.5156 - precision_12: 0.7664 - recall_12: 0.7274 - val_accuracy: 0.7347 - val_loss: 0.5409 - val_precision_12: 0.7543 - val_recall_12: 0.6927\n",
      "Epoch 4/35\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 102ms/step - accuracy: 0.7628 - loss: 0.5024 - precision_12: 0.7755 - recall_12: 0.7421 - val_accuracy: 0.7308 - val_loss: 0.5592 - val_precision_12: 0.7651 - val_recall_12: 0.6629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "428/428 - 4s - 9ms/step - accuracy: 0.7186 - loss: 0.5555 - precision_12: 0.7439 - recall_12: 0.6669\n",
      "Processing chromosome 17...\n",
      "This chromosome (17) has already been processed. Loading train/test data....\n",
      "train model on chomosome 17.....\n",
      "Epoch 1/35\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 102ms/step - accuracy: 0.7184 - loss: 0.5627 - precision_12: 0.7280 - recall_12: 0.6981 - val_accuracy: 0.7333 - val_loss: 0.5388 - val_precision_12: 0.7766 - val_recall_12: 0.6536\n",
      "Epoch 2/35\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 115ms/step - accuracy: 0.7299 - loss: 0.5472 - precision_12: 0.7427 - recall_12: 0.7044 - val_accuracy: 0.7319 - val_loss: 0.5387 - val_precision_12: 0.7790 - val_recall_12: 0.6461\n",
      "Epoch 3/35\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 94ms/step - accuracy: 0.7409 - loss: 0.5356 - precision_12: 0.7544 - recall_12: 0.7148 - val_accuracy: 0.7239 - val_loss: 0.5456 - val_precision_12: 0.7827 - val_recall_12: 0.6184\n",
      "Epoch 4/35\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.7505 - loss: 0.5206 - precision_12: 0.7657 - recall_12: 0.7224 - val_accuracy: 0.7208 - val_loss: 0.5571 - val_precision_12: 0.7965 - val_recall_12: 0.5918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "451/451 - 3s - 7ms/step - accuracy: 0.7253 - loss: 0.5441 - precision_12: 0.7770 - recall_12: 0.6319\n",
      "Processing chromosome 21...\n",
      "This chromosome (21) has already been processed. Loading train/test data....\n",
      "train model on chomosome 21.....\n",
      "Epoch 1/35\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.7251 - loss: 0.5547 - precision_12: 0.7439 - recall_12: 0.6973 - val_accuracy: 0.7389 - val_loss: 0.5290 - val_precision_12: 0.7884 - val_recall_12: 0.6507\n",
      "Epoch 2/35\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.7463 - loss: 0.5305 - precision_12: 0.7715 - recall_12: 0.7096 - val_accuracy: 0.7433 - val_loss: 0.5239 - val_precision_12: 0.7957 - val_recall_12: 0.6521\n",
      "Epoch 3/35\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.7655 - loss: 0.5105 - precision_12: 0.7871 - recall_12: 0.7360 - val_accuracy: 0.7382 - val_loss: 0.5319 - val_precision_12: 0.8030 - val_recall_12: 0.6288\n",
      "Epoch 4/35\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.7815 - loss: 0.4880 - precision_12: 0.8001 - recall_12: 0.7579 - val_accuracy: 0.7273 - val_loss: 0.5544 - val_precision_12: 0.7907 - val_recall_12: 0.6157\n",
      "Epoch 5/35\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7966 - loss: 0.4602 - precision_12: 0.8191 - recall_12: 0.7680 - val_accuracy: 0.7136 - val_loss: 0.5801 - val_precision_12: 0.7607 - val_recall_12: 0.6201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "145/145 - 1s - 7ms/step - accuracy: 0.7114 - loss: 0.5647 - precision_12: 0.7611 - recall_12: 0.6162\n",
      "Processing chromosome 10...\n",
      "This chromosome (10) has already been processed. Loading train/test data....\n",
      "train model on chomosome 10.....\n",
      "Epoch 1/35\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 90ms/step - accuracy: 0.7302 - loss: 0.5441 - precision_12: 0.7437 - recall_12: 0.7027 - val_accuracy: 0.7444 - val_loss: 0.5269 - val_precision_12: 0.7460 - val_recall_12: 0.7351\n",
      "Epoch 2/35\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 94ms/step - accuracy: 0.7468 - loss: 0.5227 - precision_12: 0.7566 - recall_12: 0.7279 - val_accuracy: 0.7391 - val_loss: 0.5294 - val_precision_12: 0.7591 - val_recall_12: 0.6948\n",
      "Epoch 3/35\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 91ms/step - accuracy: 0.7572 - loss: 0.5116 - precision_12: 0.7690 - recall_12: 0.7354 - val_accuracy: 0.7385 - val_loss: 0.5361 - val_precision_12: 0.7635 - val_recall_12: 0.6852\n",
      "Epoch 4/35\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 95ms/step - accuracy: 0.7680 - loss: 0.4970 - precision_12: 0.7780 - recall_12: 0.7501 - val_accuracy: 0.7300 - val_loss: 0.5479 - val_precision_12: 0.7648 - val_recall_12: 0.6586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "369/369 - 3s - 8ms/step - accuracy: 0.7330 - loss: 0.5396 - precision_12: 0.7329 - recall_12: 0.7331\n",
      "Processing chromosome 2...\n",
      "Chromosome 2 was not processed before. Processing...\n",
      "Loading data for chromosome 2....\n",
      "preprocessing train/test data.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 62979/62979 [09:30<00:00, 110.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 15745/15745 [02:35<00:00, 101.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model on chomosome 2.....\n",
      "Epoch 1/35\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 125ms/step - accuracy: 0.7348 - loss: 0.5406 - precision_12: 0.7492 - recall_12: 0.7086 - val_accuracy: 0.7433 - val_loss: 0.5337 - val_precision_12: 0.7386 - val_recall_12: 0.7530\n",
      "Epoch 2/35\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 126ms/step - accuracy: 0.7448 - loss: 0.5289 - precision_12: 0.7573 - recall_12: 0.7229 - val_accuracy: 0.7384 - val_loss: 0.5363 - val_precision_12: 0.7226 - val_recall_12: 0.7736\n",
      "Epoch 3/35\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 126ms/step - accuracy: 0.7552 - loss: 0.5165 - precision_12: 0.7671 - recall_12: 0.7353 - val_accuracy: 0.7386 - val_loss: 0.5364 - val_precision_12: 0.7296 - val_recall_12: 0.7582\n",
      "Epoch 4/35\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 125ms/step - accuracy: 0.7646 - loss: 0.5042 - precision_12: 0.7770 - recall_12: 0.7443 - val_accuracy: 0.7342 - val_loss: 0.5427 - val_precision_12: 0.7172 - val_recall_12: 0.7731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "662/662 - 6s - 10ms/step - accuracy: 0.7289 - loss: 0.5470 - precision_12: 0.7319 - recall_12: 0.7225\n",
      "Processing chromosome 15...\n",
      "Chromosome 15 was not processed before. Processing...\n",
      "Loading data for chromosome 15....\n",
      "preprocessing train/test data.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 62979/62979 [02:15<00:00, 465.18it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 15745/15745 [00:32<00:00, 487.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model on chomosome 15.....\n",
      "Epoch 1/35\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 133ms/step - accuracy: 0.7279 - loss: 0.5470 - precision_12: 0.7347 - recall_12: 0.7074 - val_accuracy: 0.7403 - val_loss: 0.5399 - val_precision_12: 0.7113 - val_recall_12: 0.8049\n",
      "Epoch 2/35\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 126ms/step - accuracy: 0.7418 - loss: 0.5328 - precision_12: 0.7484 - recall_12: 0.7228 - val_accuracy: 0.7433 - val_loss: 0.5363 - val_precision_12: 0.7213 - val_recall_12: 0.7892\n",
      "Epoch 3/35\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.7552 - loss: 0.5173 - precision_12: 0.7618 - recall_12: 0.7372 - val_accuracy: 0.7470 - val_loss: 0.5358 - val_precision_12: 0.7340 - val_recall_12: 0.7711\n",
      "Epoch 4/35\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - accuracy: 0.7696 - loss: 0.5005 - precision_12: 0.7738 - recall_12: 0.7570 - val_accuracy: 0.7373 - val_loss: 0.5511 - val_precision_12: 0.7147 - val_recall_12: 0.7859\n",
      "Epoch 5/35\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 126ms/step - accuracy: 0.7833 - loss: 0.4804 - precision_12: 0.7869 - recall_12: 0.7726 - val_accuracy: 0.7311 - val_loss: 0.5689 - val_precision_12: 0.7157 - val_recall_12: 0.7627\n",
      "Epoch 6/35\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - accuracy: 0.7975 - loss: 0.4582 - precision_12: 0.7972 - recall_12: 0.7940 - val_accuracy: 0.7251 - val_loss: 0.5967 - val_precision_12: 0.7137 - val_recall_12: 0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "326/326 - 4s - 11ms/step - accuracy: 0.7399 - loss: 0.5343 - precision_12: 0.7303 - recall_12: 0.7607\n",
      "Processing chromosome 9...\n",
      "Chromosome 9 was not processed before. Processing...\n",
      "Loading data for chromosome 9....\n",
      "preprocessing train/test data.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 62979/62979 [03:18<00:00, 316.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 15745/15745 [00:49<00:00, 315.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model on chomosome 9.....\n",
      "Epoch 1/35\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.7298 - loss: 0.5480 - precision_12: 0.7389 - recall_12: 0.7043 - val_accuracy: 0.7339 - val_loss: 0.5423 - val_precision_12: 0.7697 - val_recall_12: 0.6646\n",
      "Epoch 2/35\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 134ms/step - accuracy: 0.7489 - loss: 0.5270 - precision_12: 0.7605 - recall_12: 0.7210 - val_accuracy: 0.7287 - val_loss: 0.5406 - val_precision_12: 0.7693 - val_recall_12: 0.6502\n",
      "Epoch 3/35\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 124ms/step - accuracy: 0.7606 - loss: 0.5124 - precision_12: 0.7724 - recall_12: 0.7336 - val_accuracy: 0.7287 - val_loss: 0.5406 - val_precision_12: 0.7541 - val_recall_12: 0.6755\n",
      "Epoch 4/35\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - accuracy: 0.7731 - loss: 0.4953 - precision_12: 0.7809 - recall_12: 0.7542 - val_accuracy: 0.7252 - val_loss: 0.5477 - val_precision_12: 0.7639 - val_recall_12: 0.6489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "360/360 - 4s - 11ms/step - accuracy: 0.7456 - loss: 0.5272 - precision_12: 0.7792 - recall_12: 0.6853\n",
      "Processing chromosome 18...\n",
      "Chromosome 18 was not processed before. Processing...\n",
      "Loading data for chromosome 18....\n",
      "preprocessing train/test data.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 62979/62979 [01:07<00:00, 929.41it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 15745/15745 [00:17<00:00, 893.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model on chomosome 18.....\n",
      "Epoch 1/35\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.7215 - loss: 0.5505 - precision_12: 0.7353 - recall_12: 0.6900 - val_accuracy: 0.7170 - val_loss: 0.5539 - val_precision_12: 0.7127 - val_recall_12: 0.7205\n",
      "Epoch 2/35\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.7370 - loss: 0.5313 - precision_12: 0.7420 - recall_12: 0.7260 - val_accuracy: 0.7206 - val_loss: 0.5567 - val_precision_12: 0.7164 - val_recall_12: 0.7242\n",
      "Epoch 3/35\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.7541 - loss: 0.5130 - precision_12: 0.7579 - recall_12: 0.7460 - val_accuracy: 0.7156 - val_loss: 0.5701 - val_precision_12: 0.6950 - val_recall_12: 0.7616\n",
      "Epoch 4/35\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - accuracy: 0.7702 - loss: 0.4948 - precision_12: 0.7693 - recall_12: 0.7717 - val_accuracy: 0.6966 - val_loss: 0.5949 - val_precision_12: 0.6633 - val_recall_12: 0.7900\n",
      "Epoch 5/35\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - accuracy: 0.7822 - loss: 0.4733 - precision_12: 0.7769 - recall_12: 0.7919 - val_accuracy: 0.6916 - val_loss: 0.6301 - val_precision_12: 0.6543 - val_recall_12: 0.8037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "161/161 - 2s - 10ms/step - accuracy: 0.7397 - loss: 0.5221 - precision_12: 0.7299 - recall_12: 0.7609\n",
      "Processing chromosome 13...\n",
      "Chromosome 13 was not processed before. Processing...\n",
      "Loading data for chromosome 13....\n",
      "preprocessing train/test data.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 62979/62979 [01:46<00:00, 593.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 15745/15745 [00:26<00:00, 598.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model on chomosome 13.....\n",
      "Epoch 1/35\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 135ms/step - accuracy: 0.7327 - loss: 0.5451 - precision_12: 0.7401 - recall_12: 0.7199 - val_accuracy: 0.7455 - val_loss: 0.5245 - val_precision_12: 0.7449 - val_recall_12: 0.7436\n",
      "Epoch 2/35\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.7468 - loss: 0.5243 - precision_12: 0.7584 - recall_12: 0.7267 - val_accuracy: 0.7515 - val_loss: 0.5228 - val_precision_12: 0.7548 - val_recall_12: 0.7419\n",
      "Epoch 3/35\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.7620 - loss: 0.5085 - precision_12: 0.7755 - recall_12: 0.7398 - val_accuracy: 0.7455 - val_loss: 0.5258 - val_precision_12: 0.7474 - val_recall_12: 0.7385\n",
      "Epoch 4/35\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - accuracy: 0.7726 - loss: 0.4891 - precision_12: 0.7846 - recall_12: 0.7536 - val_accuracy: 0.7422 - val_loss: 0.5341 - val_precision_12: 0.7504 - val_recall_12: 0.7223\n",
      "Epoch 5/35\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.7900 - loss: 0.4665 - precision_12: 0.8005 - recall_12: 0.7744 - val_accuracy: 0.7392 - val_loss: 0.5560 - val_precision_12: 0.7359 - val_recall_12: 0.7428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "197/197 - 2s - 10ms/step - accuracy: 0.7335 - loss: 0.5437 - precision_12: 0.7559 - recall_12: 0.6896\n",
      "Processing chromosome 1...\n",
      "This chromosome (1) has already been processed. Loading train/test data....\n",
      "train model on chomosome 1.....\n",
      "Epoch 1/35\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 110ms/step - accuracy: 0.7410 - loss: 0.5344 - precision_12: 0.7507 - recall_12: 0.7233 - val_accuracy: 0.7324 - val_loss: 0.5357 - val_precision_12: 0.7635 - val_recall_12: 0.6733\n",
      "Epoch 2/35\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 114ms/step - accuracy: 0.7493 - loss: 0.5206 - precision_12: 0.7597 - recall_12: 0.7307 - val_accuracy: 0.7330 - val_loss: 0.5389 - val_precision_12: 0.7742 - val_recall_12: 0.6579\n",
      "Epoch 3/35\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 123ms/step - accuracy: 0.7587 - loss: 0.5105 - precision_12: 0.7701 - recall_12: 0.7390 - val_accuracy: 0.7332 - val_loss: 0.5415 - val_precision_12: 0.7805 - val_recall_12: 0.6490\n",
      "Epoch 4/35\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 118ms/step - accuracy: 0.7689 - loss: 0.4978 - precision_12: 0.7796 - recall_12: 0.7510 - val_accuracy: 0.7278 - val_loss: 0.5481 - val_precision_12: 0.7796 - val_recall_12: 0.6352\n",
      "Epoch 5/35\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 121ms/step - accuracy: 0.7790 - loss: 0.4856 - precision_12: 0.7889 - recall_12: 0.7630 - val_accuracy: 0.7214 - val_loss: 0.5589 - val_precision_12: 0.7793 - val_recall_12: 0.6177\n",
      "Epoch 6/35\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 113ms/step - accuracy: 0.7869 - loss: 0.4717 - precision_12: 0.7979 - recall_12: 0.7697 - val_accuracy: 0.7176 - val_loss: 0.5707 - val_precision_12: 0.7764 - val_recall_12: 0.6113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "824/824 - 8s - 10ms/step - accuracy: 0.7345 - loss: 0.5378 - precision_12: 0.7816 - recall_12: 0.6509\n",
      "Processing chromosome MT...\n",
      "Chromosome MT was not processed before. Processing...\n",
      "Loading data for chromosome MT....\n",
      "preprocessing train/test data.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 62979/62979 [00:08<00:00, 7394.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 15745/15745 [00:02<00:00, 7528.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model on chomosome MT.....\n",
      "Epoch 1/35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.4808 - loss: 0.9360 - precision_12: 0.4545 - recall_12: 0.1923 - val_accuracy: 0.6667 - val_loss: 0.5418 - val_precision_12: 0.6667 - val_recall_12: 0.6667\n",
      "Epoch 2/35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.4808 - loss: 0.8513 - precision_12: 0.4615 - recall_12: 0.2308 - val_accuracy: 0.6667 - val_loss: 0.5294 - val_precision_12: 0.6667 - val_recall_12: 0.6667\n",
      "Epoch 3/35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.4615 - loss: 0.7836 - precision_12: 0.4444 - recall_12: 0.3077 - val_accuracy: 0.6667 - val_loss: 0.5276 - val_precision_12: 0.6667 - val_recall_12: 0.6667\n",
      "Epoch 4/35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.5000 - loss: 0.7302 - precision_12: 0.5000 - recall_12: 0.4231 - val_accuracy: 0.6667 - val_loss: 0.5405 - val_precision_12: 0.6667 - val_recall_12: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "1/1 - 0s - 80ms/step - accuracy: 0.5000 - loss: 0.7447 - precision_12: 0.5000 - recall_12: 0.1250\n",
      "Processing chromosome 11...\n",
      "This chromosome (11) has already been processed. Loading train/test data....\n",
      "train model on chomosome 11.....\n",
      "Epoch 1/35\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 102ms/step - accuracy: 0.7217 - loss: 0.5578 - precision_12: 0.7347 - recall_12: 0.6970 - val_accuracy: 0.7078 - val_loss: 0.5656 - val_precision_12: 0.6781 - val_recall_12: 0.7831\n",
      "Epoch 2/35\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.7396 - loss: 0.5357 - precision_12: 0.7451 - recall_12: 0.7325 - val_accuracy: 0.7077 - val_loss: 0.5667 - val_precision_12: 0.6839 - val_recall_12: 0.7643\n",
      "Epoch 3/35\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 91ms/step - accuracy: 0.7527 - loss: 0.5195 - precision_12: 0.7597 - recall_12: 0.7424 - val_accuracy: 0.7037 - val_loss: 0.5792 - val_precision_12: 0.6817 - val_recall_12: 0.7560\n",
      "Epoch 4/35\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 90ms/step - accuracy: 0.7653 - loss: 0.5044 - precision_12: 0.7723 - recall_12: 0.7553 - val_accuracy: 0.6991 - val_loss: 0.5879 - val_precision_12: 0.6845 - val_recall_12: 0.7303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "457/457 - 4s - 8ms/step - accuracy: 0.7201 - loss: 0.5525 - precision_12: 0.6960 - recall_12: 0.7815\n",
      "Processing chromosome 14...\n",
      "This chromosome (14) has already been processed. Loading train/test data....\n",
      "train model on chomosome 14.....\n",
      "Epoch 1/35\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 90ms/step - accuracy: 0.7293 - loss: 0.5508 - precision_12: 0.7347 - recall_12: 0.7169 - val_accuracy: 0.7290 - val_loss: 0.5495 - val_precision_12: 0.7503 - val_recall_12: 0.6856\n",
      "Epoch 2/35\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 90ms/step - accuracy: 0.7444 - loss: 0.5323 - precision_12: 0.7511 - recall_12: 0.7295 - val_accuracy: 0.7177 - val_loss: 0.5557 - val_precision_12: 0.7281 - val_recall_12: 0.6939\n",
      "Epoch 3/35\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 87ms/step - accuracy: 0.7564 - loss: 0.5172 - precision_12: 0.7628 - recall_12: 0.7430 - val_accuracy: 0.7158 - val_loss: 0.5691 - val_precision_12: 0.7333 - val_recall_12: 0.6773\n",
      "Epoch 4/35\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.7707 - loss: 0.5010 - precision_12: 0.7760 - recall_12: 0.7600 - val_accuracy: 0.7139 - val_loss: 0.5900 - val_precision_12: 0.7435 - val_recall_12: 0.6519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "272/272 - 2s - 8ms/step - accuracy: 0.7383 - loss: 0.5363 - precision_12: 0.7478 - recall_12: 0.7192\n",
      "Processing chromosome 4...\n",
      "Chromosome 4 was not processed before. Processing...\n",
      "Loading data for chromosome 4....\n",
      "preprocessing train/test data.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 62979/62979 [03:35<00:00, 291.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 15745/15745 [00:51<00:00, 303.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model on chomosome 4.....\n",
      "Epoch 1/35\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - accuracy: 0.7351 - loss: 0.5307 - precision_12: 0.7469 - recall_12: 0.7095 - val_accuracy: 0.7343 - val_loss: 0.5270 - val_precision_12: 0.7531 - val_recall_12: 0.6951\n",
      "Epoch 2/35\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 89ms/step - accuracy: 0.7501 - loss: 0.5160 - precision_12: 0.7610 - recall_12: 0.7277 - val_accuracy: 0.7324 - val_loss: 0.5292 - val_precision_12: 0.7524 - val_recall_12: 0.6910\n",
      "Epoch 3/35\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.7629 - loss: 0.5000 - precision_12: 0.7740 - recall_12: 0.7413 - val_accuracy: 0.7310 - val_loss: 0.5359 - val_precision_12: 0.7473 - val_recall_12: 0.6959\n",
      "Epoch 4/35\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.7725 - loss: 0.4849 - precision_12: 0.7832 - recall_12: 0.7524 - val_accuracy: 0.7277 - val_loss: 0.5488 - val_precision_12: 0.7486 - val_recall_12: 0.6835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "361/361 - 3s - 7ms/step - accuracy: 0.7437 - loss: 0.5297 - precision_12: 0.7553 - recall_12: 0.7209\n",
      "Processing chromosome 7...\n",
      "Chromosome 7 was not processed before. Processing...\n",
      "Loading data for chromosome 7....\n",
      "preprocessing train/test data.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 62979/62979 [03:19<00:00, 315.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 15745/15745 [00:47<00:00, 332.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model on chomosome 7.....\n",
      "Epoch 1/35\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 91ms/step - accuracy: 0.7458 - loss: 0.5309 - precision_12: 0.7519 - recall_12: 0.7322 - val_accuracy: 0.7236 - val_loss: 0.5417 - val_precision_12: 0.7630 - val_recall_12: 0.6478\n",
      "Epoch 2/35\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.7594 - loss: 0.5149 - precision_12: 0.7720 - recall_12: 0.7348 - val_accuracy: 0.7189 - val_loss: 0.5440 - val_precision_12: 0.7619 - val_recall_12: 0.6359\n",
      "Epoch 3/35\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 93ms/step - accuracy: 0.7700 - loss: 0.4985 - precision_12: 0.7825 - recall_12: 0.7468 - val_accuracy: 0.7199 - val_loss: 0.5467 - val_precision_12: 0.7533 - val_recall_12: 0.6531\n",
      "Epoch 4/35\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 87ms/step - accuracy: 0.7817 - loss: 0.4841 - precision_12: 0.7936 - recall_12: 0.7603 - val_accuracy: 0.7126 - val_loss: 0.5603 - val_precision_12: 0.7509 - val_recall_12: 0.6352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "406/406 - 2s - 6ms/step - accuracy: 0.7302 - loss: 0.5381 - precision_12: 0.7701 - recall_12: 0.6562\n",
      "Processing chromosome 12...\n",
      "Chromosome 12 was not processed before. Processing...\n",
      "Loading data for chromosome 12....\n",
      "preprocessing train/test data.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 62979/62979 [02:42<00:00, 386.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 15745/15745 [00:40<00:00, 384.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model on chomosome 12.....\n",
      "Epoch 1/35\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 86ms/step - accuracy: 0.7368 - loss: 0.5348 - precision_12: 0.7513 - recall_12: 0.7066 - val_accuracy: 0.7371 - val_loss: 0.5244 - val_precision_12: 0.7487 - val_recall_12: 0.7115\n",
      "Epoch 2/35\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.7481 - loss: 0.5207 - precision_12: 0.7628 - recall_12: 0.7187 - val_accuracy: 0.7351 - val_loss: 0.5286 - val_precision_12: 0.7385 - val_recall_12: 0.7256\n",
      "Epoch 3/35\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.7589 - loss: 0.5072 - precision_12: 0.7721 - recall_12: 0.7334 - val_accuracy: 0.7327 - val_loss: 0.5353 - val_precision_12: 0.7439 - val_recall_12: 0.7074\n",
      "Epoch 4/35\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.7682 - loss: 0.4930 - precision_12: 0.7810 - recall_12: 0.7442 - val_accuracy: 0.7301 - val_loss: 0.5492 - val_precision_12: 0.7493 - val_recall_12: 0.6893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation:\n",
      "461/461 - 3s - 7ms/step - accuracy: 0.7331 - loss: 0.5365 - precision_12: 0.7528 - recall_12: 0.6941\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = build_model((WINDOW_SIZE, 4))\n",
    "\n",
    "chromosome_names = [i for i in range(1,23)] + [\"X\", \"Y\", \"MT\"]\n",
    "\n",
    "np.random.shuffle(chromosome_names)\n",
    "\n",
    "chromosome_ordinal_num = 0\n",
    "\n",
    "for i in chromosome_names:\n",
    "    filepath = f\"data/bin/train_test_data{i}.h5\" \n",
    "\n",
    "    print(f\"Processing chromosome {i}...\")\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Chromosome {i} was not processed before. Processing...\")\n",
    "    \n",
    "        # 2. load chromosome data\n",
    "        print(f\"Loading data for chromosome {i}....\")\n",
    "        chromosomes = SeqIO.to_dict(SeqIO.parse(f'data/Homo_sapiens.GRCh38.dna.chromosome.{i}.fa', 'fasta'))\n",
    "        \n",
    "        # 3. parse gtf for that chromosome\n",
    "        \n",
    "        # 4. preprocess train/test data\n",
    "        print(\"preprocessing train/test data.....\")\n",
    "        X_train, y_train = preprocess_data(train_genes, gene_groups, chromosomes, WINDOW_SIZE)\n",
    "        X_test, y_test = preprocess_data(test_genes, gene_groups, chromosomes, WINDOW_SIZE)\n",
    "        \n",
    "        # 5. save train/test data with h5\n",
    "        with h5py.File(f'data/bin/train_test_data{i}.h5', 'w') as f:\n",
    "            # Save the tuple as a dataset\n",
    "            f.create_dataset('X_train', data=X_train)\n",
    "            f.create_dataset('y_train', data=y_train)\n",
    "            f.create_dataset('X_test', data=X_test)\n",
    "            f.create_dataset('y_test', data=y_test)\n",
    "    else:\n",
    "        print(f\"This chromosome ({i}) has already been processed. Loading train/test data....\")\n",
    "        try:\n",
    "            with h5py.File(filepath, 'r') as f:\n",
    "                X_train = f['X_train'][:]\n",
    "                y_train = f['y_train'][:]\n",
    "                X_test = f['X_test'][:]\n",
    "                y_test = f['y_test'][:]\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File {file_path} not found\")\n",
    "        except KeyError as e:\n",
    "            print(f\"Error: Dataset {str(e)} not found in the file\")\n",
    "    \n",
    "    # 6. Train model on this chromosome\n",
    "    print(f\"train model on chomosome {i}.....\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=35,\n",
    "        batch_size=256,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_accuracy',\n",
    "                patience=3, \n",
    "                restore_best_weights=True),\n",
    "            # tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            #     monitor='val_loss',\n",
    "            #     factor=0.5,\n",
    "            #     patience=2\n",
    "            # )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # 7. save checkpoint model\n",
    "    model.save(f\"models/checkpoint_chr_{chromosome_ordinal_num}.h5\")\n",
    "    chromosome_ordinal_num += 1\n",
    "    \n",
    "    print(\"\\nFinal evaluation:\")\n",
    "    model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa33c6-f17b-4eb4-8a7b-7f04a23fb84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59131db-52e2-4428-9e19-34d528bc78f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89912b8e-5780-4d28-9181-db924ca63db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2839058/3023959441.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gtf = pd.read_csv(\n",
      " 34%|███████████████████████████████▏                                                            | 1921/5661 [02:55<05:42, 10.93it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m chr_test = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(chr_genes) & \u001b[38;5;28mset\u001b[39m(test_genes))\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Preprocess and save\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m X_train, y_train = \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchr_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgene_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchromosomes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWINDOW_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m X_test, y_test = preprocess_data(chr_test, gene_groups, chromosomes, WINDOW_SIZE)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m h5py.File(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata/bin/train_test_data_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.h5\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mpreprocess_data\u001b[39m\u001b[34m(gene_ids, gene_groups, chromosomes, window_size)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      6\u001b[39m     gene_data = gene_groups.get_group(gene_id)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     seqs, lbls = \u001b[43mgenerate_samples_for_gene\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgene_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchromosomes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m seqs:\n\u001b[32m      9\u001b[39m         X_data.extend(seqs)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mgenerate_samples_for_gene\u001b[39m\u001b[34m(gene_data, chromosomes, window_size)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chr_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m chromosomes:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [], []\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m chr_seq = \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchromosomes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchr_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m exon_starts = \u001b[38;5;28mset\u001b[39m(gene_data[\u001b[33m'\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m'\u001b[39m].values)\n\u001b[32m     12\u001b[39m gene_start = gene_data[\u001b[33m'\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m'\u001b[39m].min()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ExonSearch/venv/lib/python3.12/site-packages/Bio/Seq.py:410\u001b[39m, in \u001b[36m_SeqAbstractBaseClass.__str__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    409\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the full sequence as a python string.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mASCII\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Preprocess All Chromosomes First =========================================\n",
    "chromosome_names = [str(i) for i in range(1, 23)] + [\"X\", \"Y\"]\n",
    "\n",
    "# Global gene split (all chromosomes)\n",
    "gene_groups = parse_gtf(\"data/Homo_sapiens.GRCh38.113.chr.gtf.gz\") \n",
    "gene_ids = list(gene_groups.groups.keys())\n",
    "train_genes, test_genes = train_test_split(gene_ids, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Preprocess and save all chromosomes\n",
    "for chr_name in chromosome_names:\n",
    "    # Load chromosome sequence\n",
    "    chromosomes = SeqIO.to_dict(SeqIO.parse(\n",
    "        f'data/Homo_sapiens.GRCh38.dna.chromosome.{chr_name}.fa', 'fasta'\n",
    "    ))\n",
    "    \n",
    "    # Filter genes present on this chromosome\n",
    "    chr_genes = [g for g in gene_ids if gene_groups.get_group(g)['chr'].iloc[0] == chr_name]\n",
    "    chr_train = list(set(chr_genes) & set(train_genes))\n",
    "    chr_test = list(set(chr_genes) & set(test_genes))\n",
    "    \n",
    "    # Preprocess and save\n",
    "    X_train, y_train = preprocess_data(chr_train, gene_groups, chromosomes, WINDOW_SIZE)\n",
    "    X_test, y_test = preprocess_data(chr_test, gene_groups, chromosomes, WINDOW_SIZE)\n",
    "    \n",
    "    with h5py.File(f'data/bin/train_test_data_{chr_name}.h5', 'w') as f:\n",
    "        f.create_dataset('X_train', data=X_train)\n",
    "        f.create_dataset('y_train', data=y_train)\n",
    "        f.create_dataset('X_test', data=X_test) \n",
    "\n",
    "# 2. Training with Chromosome Rotation =========================================\n",
    "class ChromosomeDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, chr_files, batch_size=128):\n",
    "        self.chr_files = chr_files\n",
    "        self.batch_size = batch_size\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(sum(\n",
    "            h5py.File(f, 'r')['X_train'].shape[0] for f in self.chr_files\n",
    "        ) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get random chromosome\n",
    "        chr_file = np.random.choice(self.chr_files)\n",
    "        \n",
    "        with h5py.File(chr_file, 'r') as f:\n",
    "            X = f['X_train']\n",
    "            y = f['y_train']\n",
    "            \n",
    "            # Get random batch from chromosome\n",
    "            start = np.random.randint(0, len(X) - self.batch_size)\n",
    "            return X[start:start+self.batch_size], y[start:start+self.batch_size]\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.chr_files)\n",
    "\n",
    "# Initialize\n",
    "all_chr_files = [f'data/bin/train_test_data_{n}.h5' for n in chromosome_names]\n",
    "model = build_model((WINDOW_SIZE, 4))\n",
    "\n",
    "# Training with chromosome rotation\n",
    "history = model.fit(\n",
    "    ChromosomeDataGenerator(all_chr_files),\n",
    "    epochs=100,\n",
    "    steps_per_epoch=1000,  # Adjust based on total data size\n",
    "    validation_data=(X_test_all, y_test_all),  # Combine test sets during preprocessing\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            'best_model.h5',\n",
    "            save_best_only=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70fafb8f-3c24-435c-afca-058280a134b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 62979/62979 [00:22<00:00, 2805.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset_lazy(gene_ids, gene_groups, chromosomes, window_size):\n",
    "    for gene_id in tqdm(gene_ids):\n",
    "        try:\n",
    "            gene_data = gene_groups.get_group(gene_id)\n",
    "            seqs, lbls = generate_samples_for_gene(gene_data, chromosomes, window_size)\n",
    "            if seqs:\n",
    "                yield np.array(seqs, dtype=np.uint8), np.array(lbls, dtype=np.uint8)\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "X_train_list, y_train_list = [], []\n",
    "for X_part, y_part in load_dataset_lazy(train_genes, gene_groups, chromosomes, WINDOW_SIZE):\n",
    "    X_train_list.append(X_part)\n",
    "    y_train_list.append(y_part)\n",
    "\n",
    "X_train = np.concatenate(X_train_list)\n",
    "y_train = np.concatenate(y_train_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e7777-37ea-43bb-91f1-0767d1e4caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "\n",
    "model = build_model((WINDOW_SIZE, 4))\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=35,\n",
    "    batch_size=256,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            patience=3, \n",
    "            restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nFinal evaluation:\")\n",
    "model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save model\n",
    "model.save(\"exon_start_detector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c96991-6213-45f3-ae1f-9ef9e86c0e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
